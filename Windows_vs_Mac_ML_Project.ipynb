{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "***\n",
    "***\n",
    "***\n",
    "\n",
    "<br><h2>Unsupervised Learning Project</h2>\n",
    "<h4>Windows or Mac? | Machine Learning Course</h4>\n",
    "<br>\n",
    "Team 1: <br>\n",
    "Abdulrahim Bishar, Justyna Dmowska, Josh McCormick, Diego Antonio Giménez De Stefano, Piya Thavornwong, Peihua Tsai \n",
    "<br>\n",
    "\n",
    "Cohort: Valencia<br><br><br>\n",
    "\n",
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h2>Purpose of the analysis</h2>\n",
    "<h4>There are different aspects of consumer buying behavior, while preparing to buy a new computer: Windows or Mac. Microsoft has decided to approach this analysis from the perspective of the Big Five personality traits as well as the Hult DNA. </h4>\n",
    "<br>\n",
    "The purpose of this analysis is to use unsupervised learning to gain information and see patterns related to personality traits and how they affect laptop manufacturer preference, if they do at all. This information will be used to derive insights for Microsoft, both on their current customers and any potential customers. The data being used came from a survey containing questions which can be used to determine personality type, more specifically looking at <br>\n",
    "<a href=\"https://psychcentral.com/lib/the-big-five-personality-traits/\">'The Big Five'</a>, as well as questions about the \n",
    "<a href=\"https://www.hult.edu/blog/why-every-leader-needs-growth-mindset/\">Hult DNA</a> and demographic information.\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><h2>Domain knowledge</h2>\n",
    "<br>\n",
    "\n",
    "Before beginning to analyze the survey responses, we conducted some domain research to get a better understanding of the data we had. This research was also used to derive hypotheses. Some highlights from our research can be found below.\n",
    "<br>\n",
    "\n",
    "#### <a href=\"https://pages.uoregon.edu/sanjay/pubs/bigfive.pdf\">Sanjay & John</a> (1999)\n",
    "\n",
    "The above journal provides in depth analysis of 'The Big Five' personality traits. Sanjay would <a href=\"https://pages.uoregon.edu/sanjay/bigfive.html\">go on to summarize the traits</a> as follows:\n",
    "- **Extraversion**. The broad dimension of Extraversion encompasses such more specific traits as talkative, energetic, and assertive.\n",
    "- **Agreeableness**. Includes traits like sympathetic, kind, and affectionate.\n",
    "- **Conscientiousness**. Includes traits like organized, thorough, and planful.\n",
    "- **Neuroticism** (sometimes reversed and called Emotional Stability). Includes traits like tense, moody, and anxious.\n",
    "- **Openness to Experience** (sometimes called Intellect or intellect/Imagination). Includes traits like having wide interests, and being imaginative and insightful.\n",
    "\n",
    "\n",
    "#### <a href=\"https://www.researchgate.net/publication/259540094_I'm_a_Mac_versus_I'm_a_PC_Personality_Differences_between_Mac_and_PC_Users_in_a_College_Sample\">Nemid & Pastva</a> (2013)\n",
    "\n",
    " - Big Five personality traits did not differentiate between Mac and PC owners. Students overall rated Macs higher on various product attributes (attractive style, cool, youthful, and exciting) and PCs higher on reasonable price and good for gaming. \n",
    " - PC owners placed greater importance on cost as a determinant of brand choice, whereas Mac owners placed greater emphasis on style.  \n",
    " - Personality traits may have more nuanced effects on brand choices, as shown by relationships between Neuroticism and greater importance placed on cost and lesser importance placed on ease of use. \n",
    "     - **Personality Traits are more important in the brand choice!**\n",
    "     - More neuroticism, more importance in cost and less importance in ease of use     \n",
    "- Openness to Experience was associated with greater importance placed on reliability and lesser importance placed on style.\n",
    "    - **More openness to experience, more importance in reliability and less importance in style**\n",
    "  \n",
    "\n",
    "\n",
    "#### <a href=\"https://www.pcworld.com/article/141473/article.html\">PC World</a>\n",
    "\n",
    "A study carried out by Mindset Media for PC World found the following:\n",
    "\n",
    "- People who purchase Macs fall into what the branding company calls the \"Openness 5\" personality category -- which means they are more liberal, less modest and more assured of their own superiority than the population at large.\n",
    "-  People from Openness 5 seek rich, varied and novel experiences, according to the company, and believe that imagination and intellectual curiosity are as important to life as more rational or pragmatic endeavors.\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h2>Data preparation</h2>\n",
    "<br>\n",
    "This part includes:\n",
    "- loading libraries and dataset\n",
    "- defining helping functions, used in the further analysis\n",
    "- exploring the variables and gathering first hypothesis about them\n",
    "- dividing data into variables related to Big Five personality and Hult DNA\n",
    "- grouping survey answers, based on the domain knowledge and research\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Importing packages\n",
    "########################################\n",
    "import pandas                as pd                          # data science essentials\n",
    "import matplotlib.pyplot     as plt                         # fundamental data visualization\n",
    "import seaborn               as sns                         # enhanced visualizations\n",
    "from sklearn.preprocessing   import StandardScaler          # standard scaler\n",
    "from sklearn.decomposition   import PCA                     # pca\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage     # dendrograms\n",
    "from sklearn.cluster         import KMeans                  # k-means clustering\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Reading Data\n",
    "########################################\n",
    "my_df = pd.read_excel('Survey_Data_Final_Exam.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h4>Defining Helper functions</h4>\n",
    "<br>\n",
    "In this step, we have defined 3 functions that will be used in the further analysis. \n",
    "<br>\n",
    "- columnNamer renames columns depending if they are related to the Big 5 or to Hult DNA\n",
    "- inertia_plot shows visual representation of the clusters created in kMeans unsupervised model, in order to choose optimal number of such clusters\n",
    "- scree_plot plots all PCA components against their explained variance in the dataset, in order to chose reasonable number of such a features\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columnNamer(cols, isBigFive, isHultDna):\n",
    "    '''\n",
    "    This function renames columns depending if they are from the big 5 or \n",
    "    from Hult DNA. The format of the columns is <B5 or DNA>_Q<n>__<NAME_OF_COLUMN>.\n",
    "    \n",
    "    ----------------------\n",
    "    Params\n",
    "    ----------------------\n",
    "    \n",
    "    cols: Column name list.\n",
    "    isBigFive: Boolean. If True, function will assume that all the columns are from the big five. \n",
    "    isHuldDNA: Boolean. If True, function will assume that all the columns are from the hult dna.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "\n",
    "    cols = cols.str.lower()\n",
    "    cols = cols.str.replace(' ', '_') # Fill spaces with underscore \n",
    "    cols = cols.str.replace(\"'\", '') # Remove quotes from questions\n",
    "\n",
    "\n",
    "    if isBigFive == True:\n",
    "        _cols =  []\n",
    "        \n",
    "        for i in range(len(cols)):\n",
    "#             _cols.append(f'B5_Q{i+1}__{cols[i]}')\n",
    "            _cols.append(f'B5__{cols[i]}')\n",
    "        return _cols\n",
    "\n",
    "    elif isHultDna == True: \n",
    "\n",
    "        _cols =  []\n",
    "\n",
    "        for i in range(len(cols)):\n",
    "            _cols.append(f'DNA_Q{i+1}__{cols[i]}')\n",
    "        return _cols \n",
    "\n",
    "    else:\n",
    "        print('Call Manwe, Morgoth introduced a bug in this function')\n",
    "        \n",
    "        \n",
    "def inertia_plot(data, max_clust = 50):\n",
    "    \"\"\"\n",
    "PARAMETERS\n",
    "----------\n",
    "data      : DataFrame, data from which to build clusters. Dataset should be scaled\n",
    "max_clust : int, maximum of range for how many clusters to check interia, default 50\n",
    "    \"\"\"\n",
    "\n",
    "    ks = range(1, max_clust)\n",
    "    inertias = []\n",
    "\n",
    "\n",
    "    for k in ks:\n",
    "        # INSTANTIATING a kmeans object\n",
    "        model = KMeans(n_clusters = k)\n",
    "\n",
    "\n",
    "        # FITTING to the data\n",
    "        model.fit(data)\n",
    "\n",
    "\n",
    "        # append each inertia to the list of inertias\n",
    "        inertias.append(model.inertia_)\n",
    "\n",
    "\n",
    "\n",
    "    # plotting ks vs inertias\n",
    "    fig, ax = plt.subplots(figsize = (12, 8))\n",
    "    plt.plot(ks, inertias, '-o')\n",
    "\n",
    "\n",
    "    # labeling and displaying the plot\n",
    "    plt.xlabel('number of clusters, k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.xticks(ks)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "########################################\n",
    "# scree_plot\n",
    "########################################\n",
    "def scree_plot(pca_object, export = False):\n",
    "    # building a scree plot\n",
    "\n",
    "    # setting plot size\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    features = range(pca_object.n_components_)\n",
    "\n",
    "\n",
    "    # developing a scree plot\n",
    "    plt.plot(features,\n",
    "             pca_object.explained_variance_ratio_,\n",
    "             linewidth = 2,\n",
    "             marker = 'o',\n",
    "             markersize = 10,\n",
    "             markeredgecolor = 'black',\n",
    "             markerfacecolor = 'grey')\n",
    "\n",
    "\n",
    "    # setting more plot options\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xlabel('PCA feature')\n",
    "    plt.ylabel('Explained Variance')\n",
    "    plt.xticks(features)\n",
    "\n",
    "    if export == True:\n",
    "    \n",
    "        # exporting the plot\n",
    "        plt.savefig('top_customers_correlation_scree_plot.png')\n",
    "        \n",
    "    # displaying the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h4>Data exploration</h4>\n",
    "<br>\n",
    "\n",
    "- Missing values: <br>\n",
    "There is only 1 missing value in the ethnicity column. It will be addressed in the cleaning of the demographic data. \n",
    "<br>\n",
    "- Consistency of the categorical data: <br>\n",
    "There is one observation with the current and future laptop 'MAC', while in other observations, it is called 'Macbook'. For consistency, 'MAC' will be changed to 'Macbook' in both columns. \n",
    "<br>\n",
    "\n",
    "Value counts on the 'What laptop do you currently have?' column, after above transformation, shows rather equal representation of Windows and Macbook users in the sample (with few more customers using Macbook).\n",
    "<br>\n",
    "\n",
    "In the next step, we have created separate dataframes with variables related to Big5 personalities and Hult DNA.\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the answer 'Mac' to 'Macbook' to have more coherent data\n",
    "my_df['What laptop do you currently have?'] =  my_df['What laptop do you currently have?'].replace('MAC', 'Macbook')\n",
    "my_df['What laptop would you buy in next assuming if all laptops cost the same?'] =  my_df['What laptop would you buy in next assuming if all laptops cost the same?'].replace('MAC', 'Macbook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling value counts on the laptops that consumers currently have to see initial distribution\n",
    "# my_df.loc[:,'What laptop do you currently have?'].value_counts()\n",
    "\n",
    "## Output\n",
    "## Macbook           200\n",
    "## Windows laptop    192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h4>Demographic variables</h4>\n",
    "\n",
    "Demographic Variables are renamed in this section. The following variables are considered as demographic variables:\n",
    "\n",
    "- 'What laptop do you currently have?',\n",
    "- 'What laptop would you buy in next assuming if all laptops cost the same?',\n",
    "- 'What program are you in?', \n",
    "- 'What is your age?', \n",
    "- 'Gender',\n",
    "- 'What is your nationality? ', \n",
    "- 'What is your ethnicity?'\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming Demographic Data\n",
    "\n",
    "# Creating a dictionary\n",
    "columns_to_change = dict(zip([\n",
    "        'What laptop do you currently have?',\n",
    "        'What laptop would you buy in next assuming if all laptops cost the same?',\n",
    "        'What program are you in?', \n",
    "        'What is your age?', \n",
    "        'Gender',\n",
    "        'What is your nationality? ', \n",
    "        'What is your ethnicity?'], \n",
    "        \n",
    "       ['Current laptop', \n",
    "        'Next laptop', \n",
    "        'Program', \n",
    "        'Age', \n",
    "        'Gender',\n",
    "        'Nationality', \n",
    "        'Ethnicity'\n",
    "    ]\n",
    "))\n",
    "\n",
    "my_df.rename(columns_to_change,\n",
    "                   axis='columns',inplace=True)\n",
    "\n",
    "# Renaming Big 5 Data \n",
    "# Separated Big 5 Data set\n",
    "big_five = my_df.iloc[:, 1:51]  # Subset big five-related columns\n",
    "\n",
    "# Change Column Names\n",
    "big_five.columns = columnNamer(big_five.columns,\n",
    "                               isBigFive=True,\n",
    "                               isHultDna=False)\n",
    "\n",
    "\n",
    "# Creating demographic Variables \n",
    "demographics = my_df.loc[:,  ['Current laptop', \n",
    "        'Next laptop', \n",
    "        'Program', \n",
    "        'Age', \n",
    "        'Gender',\n",
    "        'Nationality', \n",
    "        'Ethnicity'                     \n",
    "    ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><strong>Age</strong><br><br>\n",
    "We checked the age of people who filled the survey, and see if we can group them together in the range.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder_lst = []\n",
    "\n",
    "for age in my_df['Age']:\n",
    "    \n",
    "    if age <= 20:\n",
    "        age_range = '<20'\n",
    "    \n",
    "    elif age > 20 and age <= 25:\n",
    "        age_range = '20-25'\n",
    "    \n",
    "    elif age > 25 and age <= 30:\n",
    "        age_range = '26-30'\n",
    "        \n",
    "    elif age > 30 and age <= 35:\n",
    "        age_range = '31-35'\n",
    "    \n",
    "    elif age > 36 and age <= 40:\n",
    "        age_range = '36-40'\n",
    "        \n",
    "    elif age > 40:\n",
    "        age_range = '>40'\n",
    "        \n",
    "    placeholder_lst.append(age_range)\n",
    "    \n",
    "my_df['age_range'] = placeholder_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><strong>Nationality</strong><br><br>\n",
    "We checked the nationality of people who filled the survey. We can see that the data are dirty because the survey let people type the responses by themselves. We can clean the data by grouping the same nationality together.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder_lst = []\n",
    "\n",
    "# create a list for nationality change\n",
    "nation_change = [[['china'],'chinese'],\n",
    "                 [['peru'], 'peruvian'],\n",
    "                 [['mexico'], 'mexican'],\n",
    "                 [['usa'], 'american'],\n",
    "                 [['russia'], 'russian'],\n",
    "                 [['ecuador'], 'ecuadorian'],\n",
    "                 [['brazil'], 'brazilian'],\n",
    "                 [['nigeria'], 'nigerian'],\n",
    "                 [['korea','republicofkorea','southkorea'],'korean'],\n",
    "                 [['spain'],'spanish'],\n",
    "                 [['indonesia'],'indonesian'],\n",
    "                 [['germany'],'german'],\n",
    "                 [['colombia'], 'colombian'],\n",
    "                 [['taiwan', 'taiwan(roc)'], 'taiwanese'],\n",
    "                 [['japan'], 'japanese'],\n",
    "                 [['canada'], 'canadian'],\n",
    "                 [['philippines'], 'filipino'],\n",
    "                 [['thailand'], 'thai'],\n",
    "                 [['india'], 'indian'],\n",
    "                 [['czechrepublic'], 'czech'],\n",
    "                 [['belgium'], 'belgian'],\n",
    "                 [['english'], 'british'],\n",
    "                 [['ghana'], 'ghanaian'],\n",
    "                 [['.', 'hispanic'], 'prefernottoanswer'],\n",
    "                 [['italianandspanish', 'german/american', 'french/brazilian', 'british,indian', 'caribbean-american'], 'multi-ethnic'],\n",
    "                 [['costarica'], 'costarrican'],\n",
    "                 [['congolese(drcongo)'], 'congolese'],\n",
    "                 [['venezuela'],'venezuelan'],\n",
    "                 [['dominicanrepublic'],'dominican']\n",
    "                \n",
    "                ]\n",
    "\n",
    "# create a for loop\n",
    "for nationality in my_df['Nationality']:\n",
    "    \n",
    "    # remove \" \" and \".\"\n",
    "    nationality = nationality.lower().replace(\" \",\"\").replace(\".\",\"\")\n",
    "    \n",
    "    # create a loop\n",
    "    for old_nat, new_nat in nation_change:\n",
    "    \n",
    "        # create if statement to check if nationality is wrong\n",
    "        if nationality in old_nat:\n",
    "            nationality = new_nat\n",
    "    \n",
    "    # append the correct nationality to a list\n",
    "    placeholder_lst.append(nationality)\n",
    "\n",
    "# create a new column\n",
    "my_df['Nationality2'] = placeholder_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "We can group nationality together by continent to reduce amount of nationality groups.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# create a for loop\n",
    "for nationality in my_df['Nationality2']:\n",
    "    \n",
    "    # check if nationality is in Asia\n",
    "    if nationality in ['indian','chinese','taiwanese','filipino','korean',\n",
    "                       'thai','indonesian','vietnamese','japanese','palestinian',\n",
    "                       'kyrgyz','pakistani','bangladeshi','iran','malaysia']:\n",
    "        nationality = 'Asian'\n",
    "    \n",
    "    # check if nationality is in Europe\n",
    "    elif nationality in ['german','russian','italian','spanish','norwegian',\n",
    "                         'turkish','belgian','czech','british','swiss',\n",
    "                         'ukrainian','portuguese','belarus','dutch','poland',\n",
    "                         'armenia','dutch']:\n",
    "        nationality = 'European'\n",
    "    \n",
    "    # check if nationality is in North America\n",
    "    elif nationality in ['mexican','american','canadian','dominican','costarrican',\n",
    "                         'panama','guatemalan','elsalvador','honduran']:\n",
    "        nationality = 'North American'\n",
    "    \n",
    "    # check if nationality is in South America\n",
    "    elif nationality in ['peruvian','colombian','brazilian','ecuadorian',\n",
    "                         'venezuelan']:\n",
    "        nationality = 'South American'\n",
    "    \n",
    "    # check if nationality is in Africa\n",
    "    elif nationality in ['nigerian','kenyan','congolese','ghanaian','ugandan',\n",
    "                         'mauritius','southafrican','cameroon']:\n",
    "        nationality = 'Africa'\n",
    "    \n",
    "    # check if nationality is multi-ethnic\n",
    "    elif nationality == 'multi-ethnic':\n",
    "        nationality = 'multi-ethnic'\n",
    "    \n",
    "    # put 'prefernottoanswer' for the remaining\n",
    "    else: \n",
    "        nationality = 'prefernottoanswer'\n",
    "    \n",
    "    # append the new nationality group to a list\n",
    "    placeholder_lst.append(nationality)\n",
    "\n",
    "# create a new column\n",
    "my_df['Nationality_continent'] = placeholder_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h4>Hypotheses about laptop users</h4>\n",
    "<br>\n",
    "\n",
    "Based on the external research, presented earlier, we have created some initial hypotheses about Mac and Windows users:\n",
    "<br>\n",
    "\n",
    "- Mac users will have more opennes to new adventures based on the PC World research\n",
    "- Mac users are more extroverted than windows users. <a href=\"https://mashable.com/2011/04/23/mac-vs-pc-infographic/\">This infographic</a> created by Hunch states that Windows users are 26% more likely to prefer fitting in with others, while Mac users are 50% more likely to say they frequently throw parties.\n",
    "- Windows users will be more conscientious than Mac users. <a href=\"https://www.neosperience.com/blog/the-new-marketing-is-people-centric-know-your-customer-personality/\">It has been said</a> that when purchasing, conscientious customers 'look for the utilitarian, functional, task-related, and rational value of shopping'. \n",
    "<br>\n",
    "\n",
    "In the next part of this work, we will create models and derive insights, which will be tested against those initial hypotheses.\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br><h4>Determining Customer Types</h4>\n",
    "<br>\n",
    "\n",
    "The initial plan was to split each respondent in to one of 4 customer types; Loyal Windows, Loyal Macbook, Windows Deserter and Macbook Deserter. However, as can be seen below, when doing this the 'Macbook Deserter' group was too small to use as a sample.\n",
    "<br>\n",
    "\n",
    "It should still be noted that only 10% of current Macbook users would switch to a different brand of laptop, compared with 23% of Windows users. This shows that there is less brand loyalty towards Windows laptops than Macbook's. We would recommend Microsoft carry out more research in to users who are willing to change laptop brands in order to gain a deeper understanding of their own customers who would consider leaving, as well as Macbook customers they could potentially poach.\n",
    "<br>\n",
    "\n",
    "Value Counts with the initial approach:\n",
    "~~~\n",
    "Loyal Macbook       181\n",
    "Loyal Windows       147\n",
    "Windows Deserter     45\n",
    "Macbook Deserter     19\n",
    "~~~\n",
    "<br>\n",
    "\n",
    "In order to avoid a sampling issue, we have decided to use three customer types instead. For Microsoft, it will be important to understand the personalities of the audience, depending on their purchasing preferences. Our three customer types are:\n",
    "- Loyal Windows - Currently own a Windows laptop and would buy a Windows laptop next\n",
    "- Loyal Macbook - Currently own a Macbook and would buy a Macbook next\n",
    "- Not Brand Loyal - Users who said their next laptop will be a different brand to the one they currently have.\n",
    "<br>\n",
    "\n",
    "With these groups, we'll gain a better understanding of if certain personality types lead to brand loyalty, or lack of loyalty, to Windows or Macbook.\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to determine customer type\n",
    "\n",
    "for index, row in my_df.iterrows():\n",
    "    if 'Windows laptop' in row['Current laptop'] and 'Windows laptop' in row['Next laptop']:\n",
    "        my_df.loc[index, 'customer_type'] = 'Loyal Windows' \n",
    "   \n",
    "    elif 'Macbook' in row['Current laptop'] and 'Macbook' in row['Next laptop']:\n",
    "        my_df.loc[index, 'customer_type'] = 'Loyal Macbook'\n",
    "        \n",
    "    elif row['Current laptop'] != row['Next laptop']:\n",
    "        my_df.loc[index, 'customer_type'] = 'Not Brand Loyal'      \n",
    "        \n",
    "    else:\n",
    "        my_df.loc[index, 'customer_type'] = 'error'\n",
    "        \n",
    "# Checking the results\n",
    "# my_df['customer_type'].value_counts()\n",
    "\n",
    "### Output\n",
    "# # Loyal Macbook      181\n",
    "# # Loyal Windows      147\n",
    "# # Not Brand Loyal     64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h4>Creation of Big5 factors</h4>\n",
    "<br>\n",
    "\n",
    "Based on the study, presented earlier, we have created 5 variables, related to Big 5 personalities:\n",
    "- extraversion\n",
    "- agreeableness\n",
    "- conscientiousness\n",
    "- emotional_stability\n",
    "- intellect\n",
    "<br>\n",
    "\n",
    "As some of the features from the original survey contribute negatively to the above personalities, as a first step, we have fixed those negative factors.\n",
    "\n",
    "Source:\n",
    "\n",
    "- https://ipip.ori.org/newBigFive5broadKey.htm#Conscientiousness\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Big 5 and Hult DNA datasets\n",
    "big_five = my_df.iloc[:, 1:51] # Subset big five-related columns\n",
    "hult_dna = my_df.iloc[:,51:72] # Subset Hult DNA\n",
    "\n",
    "\n",
    "\n",
    "# Change Column Names, using columnNamer function\n",
    "big_five.columns = columnNamer(big_five.columns,\n",
    "            isBigFive=True, \n",
    "            isHultDna=False)\n",
    "\n",
    "hult_dna.columns = columnNamer(hult_dna.columns,\n",
    "            isBigFive=False,\n",
    "           isHultDna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing negative factors\n",
    "\n",
    "#### Factor I (Surgency or Extraversion)\n",
    "\n",
    "fac1_pos = [\n",
    "    \"am the life of the party\",\n",
    "    \"Feel comfortable around people\",\n",
    "    \"Start conversations\", \n",
    "    \"Talk to a lot of different people at parties\",\n",
    "    \"Don't mind being the center of attention\"\n",
    "    ]\n",
    "\n",
    "fac1_neg = [ \n",
    "    \"Don't talk a lot\", \n",
    "    \"Keep in the background\", \n",
    "    \"Have little to say\",\n",
    "    \"Don't like to draw attention to myself\", \n",
    "    \"Am quiet around strangers\"\n",
    "]\n",
    "\n",
    "## Factor II (Agreeableness)\n",
    "\n",
    "fac2_pos = [\n",
    "    \"Am interested in people\", \n",
    "    \"Sympathize with others' feelings\",\n",
    "    \"Have a soft heart\", \n",
    "    \"Take time out for others\", \n",
    "    \"Feel others' emotions\",\n",
    "    \"Make people feel at ease\"\n",
    "    ]\n",
    "\n",
    "fac2_neg = [\n",
    "    \"Am not really interested in others\", \n",
    "    \"Insult people\",\n",
    "    \"Am not interested in other people's problems\",\n",
    "    \"Feel little concern for others\"\n",
    "]\n",
    "\n",
    "\n",
    "## Factor III (Conscientiousness)\n",
    "\n",
    "fac3_pos = [\n",
    "    \"Am always prepared\", \n",
    "    \"Pay attention to details\",\n",
    "    \"Get chores done right away\",\n",
    "    \"Like order\", \n",
    "    \"Follow a schedule\",\n",
    "    \"Am exacting in my work\"\n",
    "]\n",
    "\n",
    "fac3_neg = [\n",
    "    \"Leave my belongings around\", \n",
    "    \"Make a mess of things\",\n",
    "    \"Often forget to put things back in their proper place\",\n",
    "    \"Shirk my duties\"\n",
    "]\n",
    "\n",
    "##Factor IV (Emotional Stability)\n",
    "\n",
    "fac4_pos = [\n",
    "            \"Am relaxed most of the time\", \n",
    "            \"Seldom feel blue\"\n",
    "]\n",
    "\n",
    "fac4_neg = [\n",
    "    \"Get stressed out easily\",\n",
    "    \"Worry about things\", \n",
    "    \"Am easily disturbed\",\n",
    "    \"Get upset easily\",\n",
    "    \"Change my mood a lot\", \n",
    "    \"Have frequent mood swings\",\n",
    "    \"Get irritated easily\",\n",
    "    \"Often feel blue\"\n",
    "]\n",
    "\n",
    "## Factor V (Intellect or Imagination)\n",
    "\n",
    "fac5_pos = [\n",
    "    \"Have a rich vocabulary\",\n",
    "    \"Have a vivid imagination\",\n",
    "    \"Have excellent ideas\", \n",
    "    \"Am quick to understand things\",\n",
    "    \"Use difficult words\", \n",
    "    \"Spend time reflecting on things\",\n",
    "    \"Am full of ideas\"\n",
    "]\n",
    "\n",
    "fac5_neg = [\n",
    "    \"Have difficulty understanding abstract ideas\",\n",
    "    \"Am not interested in abstract ideas\",\n",
    "    \"Do not have a good imagination\"\n",
    "]\n",
    "\n",
    "\n",
    "# Concat all negative factors to reverse them \n",
    "\n",
    "fac_all_neg = fac1_neg + fac2_neg + fac3_neg + fac4_neg + fac5_neg\n",
    "\n",
    "fac_all_neg_cols = columnNamer(pd.Series(fac_all_neg), isBigFive=True, isHultDna=False)\n",
    "\n",
    "\n",
    "## Transforming Reversed Items.\n",
    "big_five.loc[:,fac_all_neg_cols].replace(5,1, inplace= True)\n",
    "big_five.loc[:, fac_all_neg_cols].replace(4,2, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Factors based on Original Study\n",
    "fac1_all = fac1_pos + fac2_neg\n",
    "fac2_all = fac2_pos + fac2_neg\n",
    "fac3_all = fac3_pos + fac3_neg\n",
    "fac4_all = fac4_pos + fac4_neg\n",
    "fac5_all = fac4_pos + fac5_neg\n",
    "\n",
    "big_five_final = pd.DataFrame(\n",
    "\n",
    "{\n",
    "    'extraversion':big_five[columnNamer(pd.Series(fac1_all), isBigFive=True, isHultDna=False)].sum(axis = 1),\n",
    "\n",
    "    'agreeableness':big_five[columnNamer(pd.Series(fac2_all), isBigFive=True, isHultDna=False)].sum(axis = 1),\n",
    "\n",
    "    'conscientiousness':big_five[columnNamer(pd.Series(fac3_all), isBigFive=True, isHultDna=False)].sum(axis = 1),\n",
    "    \n",
    "    'emotional_stability':big_five[columnNamer(pd.Series(fac4_all), isBigFive=True, isHultDna=False)].sum(axis = 1),\n",
    "\n",
    "    'intellect':big_five[columnNamer(pd.Series(fac5_all), isBigFive=True, isHultDna=False)].sum(axis = 1)\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h2>Big Five</h2>\n",
    "<br>\n",
    "This section includes:\n",
    "- scaling data\n",
    "- KMeans clustering\n",
    "- using Big 5 personalities as main components for modeling\n",
    "<br>\n",
    "\n",
    "The team has decided to proceed directly with KMeans clustering. Our reasoning is based on the fact that Goldberg's Big Five instrument used PCA to be developed (Exploratory Factor Analysis). Thus, we grouped the items according to the original author of the instrument and decided to cluster users by the originally traits of personality that were defined in Goldberg (1992).\n",
    "<br>\n",
    "\n",
    "Sources:<br>\n",
    "- <a href=\"https://ipip.ori.org/newBigFive5broadKey.htm#Conscientiousness\">Big-Five Factor Markers</a> <br>\n",
    "- <a href=\"https://ipip.ori.org/newBigFive5broadTable.htm\">Measuring the Big-Five Domains</a> \n",
    "- Goldberg, L. R. (1992). The development of markers for the Big-Five factor structure. Psychological Assessment, 4, 26-42.\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a StandardScaler() object\n",
    "st_scaler = StandardScaler()\n",
    "\n",
    "# FITTING and TRANSFORMING the data\n",
    "big_five_scaled = st_scaler.fit_transform(big_five_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using inertia_plot function to visualize the number of possible clusters\n",
    "# Cutoff point: 2 clusters\n",
    "inertia_plot(big_five_scaled,max_clust=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h3>Chosing number of clusters</h3>\n",
    "<br>\n",
    "\n",
    "After few trials, we have decided to stay with 2 clusters because is dividing the data points in a best manner and it creates two, similar in size groups of observations, substantially different from each other (based on the value of the Big 5 factors). \n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clustering\n",
    "\n",
    "# INSTANTIATING a k-Means object with two clusters\n",
    "k_means_big5 = KMeans(n_clusters=2,\n",
    "                        random_state = 802)\n",
    "\n",
    "\n",
    "# fitting the object to the data\n",
    "k_means_big5_fit = k_means_big5.fit(big_five_scaled)\n",
    "\n",
    "# converting the clusters to a DataFrame\n",
    "k_means_big5_clusters = pd.DataFrame({'Kmeans':k_means_big5_fit.labels_})\n",
    "\n",
    "\n",
    "# checking the results\n",
    "# k_means_big5_clusters.iloc[:,0].value_counts() # Both clusters are balanced and well differentiated\n",
    "\n",
    "### Output from Value Counts\n",
    "# # 1    202\n",
    "# # 0    190"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting Cluster Centroids\n",
    "<br> \n",
    "\n",
    "The first cluster grouped users that had lower average scores across the Big Five factors. Conversely, the second clusters grouped users that were above the sample's mean (standardization has 0 as mean, 1 as standard deviation). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing cluster centers\n",
    "centroids_big5 = k_means_big5_fit.cluster_centers_\n",
    "\n",
    "\n",
    "# converting cluster centers into a DataFrame\n",
    "centroids_big5_df = pd.DataFrame(centroids_big5)\n",
    "\n",
    "\n",
    "# renaming principal componentswith Big5 factors\n",
    "centroids_big5_df.columns = big_five_final.columns\n",
    "\n",
    "\n",
    "# checking results (clusters = rows, Big5 personalities = columns)\n",
    "centroids_big5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data frame with Big5 factors names\n",
    "big_five_scaled_df = pd.DataFrame(big_five_scaled, \n",
    "                                  columns = ['extraversion',\n",
    "                                             'agreeableness',\n",
    "                                             'conscientiousness',\n",
    "                                             'emotional_stability',\n",
    "                                             'intellect'])\n",
    "\n",
    "# creating dataframe for the created demographics\n",
    "demographics_created = my_df[['age_range', 'Nationality2','Nationality_continent','customer_type']]\n",
    "\n",
    "# creating Big5 merged dataframe with demographics\n",
    "data_df = pd.concat([k_means_big5_clusters, demographics, demographics_created, big_five_scaled_df], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h3>Demographics with Big5 analysis</h3>\n",
    "<br>\n",
    "\n",
    "This part consists of testing hypothesis about laptop buyers, in relation to their demographics and Big5 personalities traits.\n",
    "Boxplots were used to visually represent different clusters, traits and demographic categories.\n",
    "<br>\n",
    "\n",
    "Hypotheses to be tested (as they were established at the beginning of this analysis):\n",
    "- Mac users will have more opennes to new adventures \n",
    "    - For the current laptops - the H1 is confirmed, in the cluster 0\n",
    "    - For the next laptops - the H1 is not confirmed\n",
    "    - For the customer_type - the H1 is confirmed, loyal Mac users are the most open in cluster 0\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "- Mac users are more extroverted than windows users\n",
    "    - For the current laptops - the H2 is confirmed, in both clusters\n",
    "    - For the next laptops - the H2 is confirmed in the cluster 0, but not confirmed in the cluster 1\n",
    "    - For the customer_type - the H2 is confirmed, Mac users are the most extravertic in both clusters\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "- Windows users will be more conscientious than Mac users\n",
    "    - For the current laptops - the H3 is confirmed for cluster 0. In cluster 1, there is almost no difference.\n",
    "    - For the next laptops - the H3 is confirmed for cluster 1. In cluster 0, there is almost no difference.\n",
    "    - For the customer_type - the H3 is confirmed, Windows users are most conscientious in cluster 1 \n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# H1: Mac users will have more opennes to new adventures\n",
    "\n",
    "########################\n",
    "# Current laptop\n",
    "########################\n",
    "\n",
    "# intellect\n",
    "# fig, ax = plt.subplots(figsize = (12, 8))\n",
    "# sns.boxplot(x = 'Kmeans',\n",
    "#             y = 'intellect',\n",
    "#             hue = 'Current laptop',\n",
    "#             data = data_df )\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# For the current laptops - the H1 is confirmed, in the cluster 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H1: Mac users will have more opennes to new adventures\n",
    "\n",
    "########################\n",
    "# Next laptop\n",
    "########################\n",
    "\n",
    "# intellect\n",
    "# fig, ax = plt.subplots(figsize = (12, 8))\n",
    "# sns.boxplot(x = 'Kmeans',\n",
    "#             y = 'intellect',\n",
    "#             hue = 'Next laptop',\n",
    "#             data = data_df )\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# For the next laptops - the H1 is not confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H2: Mac users are more extroverted than windows users\n",
    "\n",
    "########################\n",
    "# Current laptop\n",
    "########################\n",
    "\n",
    "### extraversion\n",
    "# fig, ax = plt.subplots(figsize = (12, 8))\n",
    "# sns.boxplot(x = 'Kmeans',\n",
    "#             y = 'extraversion',\n",
    "#             hue = 'Current laptop',\n",
    "#             data = data_df )\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# For the current laptops - the H2 is confirmed, in both clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H2: Mac users are more extroverted than windows users\n",
    "\n",
    "########################\n",
    "# Next laptop\n",
    "########################\n",
    "\n",
    "# extraversion\n",
    "# fig, ax = plt.subplots(figsize = (12, 8))\n",
    "# sns.boxplot(x =  'Kmeans',\n",
    "#             y = 'extraversion',\n",
    "#             hue ='Next laptop',\n",
    "#             data = data_df )\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# For the next laptops - the H2 is confirmed in the cluster 0, but not confirmed in the cluster 1\n",
    "# what is interesting future Chrome users from cluster 0 are even more extroverted than both future Mac and Windows users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H3: Windows users will be more conscientious than Mac users\n",
    "\n",
    "########################\n",
    "# Current laptop\n",
    "########################\n",
    "\n",
    "# conscientiousness\n",
    "# fig, ax = plt.subplots(figsize = (12, 8))\n",
    "# sns.boxplot(x = 'Kmeans',\n",
    "#             y = 'conscientiousness',\n",
    "#             hue = 'Current laptop',\n",
    "#             data = data_df )\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# For the current laptops - the H3 is confirmed for cluster 0. In cluster 1, there is almost no difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H3: Windows users will be more conscientious than Mac users\n",
    "\n",
    "########################\n",
    "# Next laptop\n",
    "########################\n",
    "\n",
    "# conscientiousness\n",
    "# fig, ax = plt.subplots(figsize = (12, 8))\n",
    "# sns.boxplot(x = 'Kmeans',\n",
    "#             y = 'conscientiousness',\n",
    "#             hue = 'Next laptop',\n",
    "#             data = data_df )\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# For the next laptops - the H3 is confirmed for cluster 1. In cluster 0, there is almost no difference.\n",
    "# what is interesting future Chrome users from cluster 0 are even more conscientious than both future Mac and Windows users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H1: Mac users will have more opennes to new adventures\n",
    "\n",
    "########################\n",
    "# customer_type\n",
    "########################\n",
    "\n",
    "# intellect\n",
    "# fig, ax = plt.subplots(figsize = (12, 8))\n",
    "# sns.boxplot(x = 'Kmeans',\n",
    "#             y = 'intellect',\n",
    "#             hue = 'customer_type',\n",
    "#             data = data_df )\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# For the customer_type - the H1 is confirmed, loyal Mac users are the most open in cluster 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H2: Mac users are more extroverted than windows users\n",
    "\n",
    "########################\n",
    "# customer_type\n",
    "########################\n",
    "\n",
    "## extraversion\n",
    "fig, ax = plt.subplots(figsize = (12, 8))\n",
    "sns.boxplot(x = 'Kmeans',\n",
    "            y = 'extraversion',\n",
    "            hue = 'customer_type',\n",
    "            data = data_df )\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# For the customer_type - the H2 is confirmed, Mac users are the most extravertic in both clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# H3: Windows users will be more conscientious than Mac users\n",
    "\n",
    "########################\n",
    "# customer_type\n",
    "########################\n",
    "\n",
    "# conscientiousness\n",
    "# fig, ax = plt.subplots(figsize = (12, 8))\n",
    "# sns.boxplot(x = 'Kmeans',\n",
    "#             y = 'conscientiousness',\n",
    "#             hue = 'customer_type',\n",
    "#             data = data_df )\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# For the customer_type - the H3 is confirmed, Windows users are most conscientious in cluster 1 \n",
    "# However, in cluster 0, the most conscientious are the ones who will switch the brand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Users Analysis - Risk to Churn\n",
    "\n",
    "Users were segmented in the following way \n",
    "- Low Risk to Churn: Current Laptop Windows & Next Laptop Windows\n",
    "- High risk to churn: Current Laptop Windows & Next Laptop Not Windows\n",
    "\n",
    "<br> \n",
    "\n",
    "- Findings: \n",
    "\n",
    "    - Users that are on risk to churn are less extroverted, less agreeable, more conscious, less emotionally stable\n",
    "    - User that are not on risk to churn are more extroverted, more agreeable, less conscious, and more emotionally stable \n",
    "    \n",
    "<br>\n",
    "\n",
    "Users that have less risk to churn are more extroverted and less conscious compared to users that are at high risk to churn. According to Ercis & Ünalan (2017), users that are more extroverted and less conscious are related to compulsive buying behaviors. \n",
    "\n",
    "\n",
    "<br> \n",
    "\n",
    "References\n",
    "-   Erciş A. & Ünalan, M. (2017). Relationship among big five personality traits, compulsive buying and variety seeking. Journal of Management, Marketing and Logistics. 4. 217-223. 10.17261/Pressacademia.2017.483. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Participants with Low Churn Risk \n",
    "\n",
    "# data_df[(data_df['Current laptop'] == 'Windows laptop') & (data_df['Next laptop'] == 'Windows laptop')].mean()\n",
    "\n",
    "### Output \n",
    "# extraversion           -0.070334\n",
    "# agreeableness           0.031075\n",
    "# conscientiousness      -0.019639\n",
    "# emotional_stability    -0.159245\n",
    "# intellect               0.083173\n",
    "\n",
    "\n",
    "## Participants with High Churn Risk\n",
    "\n",
    "# data_df[(data_df['Current laptop'] == 'Windows laptop') & (data_df['Next laptop'] == 'Macbook')].mean()\n",
    "\n",
    "### Output\n",
    "# extraversion           -0.537374\n",
    "# agreeableness          -0.063542\n",
    "# conscientiousness       0.039607\n",
    "# emotional_stability    -0.291014\n",
    "# intellect              -0.065956\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h2>Hult DNA analysis</h2>\n",
    "<br>\n",
    "\n",
    "This part consists of testing hypothesis about laptop buyers, in relation to their demographics and Hult DNA.\n",
    "\n",
    "Hult DNA is a leadership skill available on <a href = \"https://www.hult.edu/blog/why-every-leader-needs-growth-mindset/\">Hult's website</a>. It is separated into 3 topics with sub-topics.<br>\n",
    "\n",
    "- Thinking<br>\n",
    "    - Show Self-Awareness\n",
    "    - Embraces Change\n",
    "    - Demonstrates Dynamic Thinking<br><br>\n",
    "- Communicating<br>\n",
    "    - Speaks & Listens Skillfully\n",
    "    - Influences Confidently\n",
    "    - Present Ideas Effectively<br><br>\n",
    "- Team Building<br>\n",
    "    - Fosters Collaborative Relationships\n",
    "    - Inspires Productivity\n",
    "    - Resolves Conflict Constructively<br><br>\n",
    "  \n",
    "\n",
    "According to the <a href = \"https://kellynford.com/2009/11/24/mac-vs-pc-people-personality-traits-aestheticmedia-choices/\">article</a> form Kelly Ford, Window users are likely to describe themselves as “numbers-oriented”, “factual” and “steady, hard workers”. It is an interesting topic that we can check if the Window user represented more oriented or steady in the Hult DNA.<br>\n",
    "\n",
    "We have 20 questions in this survey that are related to Hult DNA. We can analyze it to see if the leadership skills affect the decision of using or buying a Windows laptop.<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hult_dna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hult_dna.columns = ['DNA_1', 'DNA_2', 'DNA_3', 'DNA_4', 'DNA_5', 'DNA_6', 'DNA_7',\n",
    "              'DNA_8', 'DNA_9', 'DNA_10', 'DNA_11', 'DNA_12', 'DNA_13', \n",
    "              'DNA_14', 'DNA_15', 'DNA_16', 'DNA_17', 'DNA_18', 'DNA_19', \n",
    "              'DNA_20', 'DNA_21']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Hult DNA Grouping </h2>\n",
    "\n",
    "Most of the questions are asked in a direct manner and use a positive connotation e.g. \"Are you satisfied\"\n",
    "and so from the scale 1 to 5, the higher the more satisfied.\n",
    "\n",
    "<br>\n",
    "\n",
    "However, if the question is twisted into \"Are you not satisfied?\" which uses a negative connotation, then from scale 1 to 5, the lower the more satisfied.\n",
    "\n",
    "<br>\n",
    "\n",
    "In the dataset, only DNA_2, DNA_12 and DNA_16 are asked in a negative connotation.\n",
    "In order to standardize the question, we switch answers of 5 to 1, 4 to 2, 3 stays at 3,\n",
    "2 to 4, 1 to 5 so the value is at the same direction of the scale as other Hult DNA questions.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Step 1**: Create an empty list\n",
    "- **Step 2**: Using for loop to loop over the original column\n",
    "- **Step 3**: Feed the new value to the blank list\n",
    "- **Step 4**:  Feed the new column with the list which is no longer the blank list \n",
    "since Step 3, the blank list has the new value\n",
    "\n",
    "<br> \n",
    "______________\n",
    "<br> \n",
    "\n",
    "<strong> DNA_2, DNA_12 and DNA_16 </strong> will undergo the Step1 to Step4, \n",
    "the new columns <strong> DNA_2n, DNA_12n and DNA_16n will be created </strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Standardize the columns for negative question \n",
    "########################################\n",
    "\n",
    "change = ['DNA_2', 'DNA_12', 'DNA_16']\n",
    "\n",
    "for column in change:\n",
    "\n",
    "    placeholder_lst = []\n",
    "\n",
    "    for value in hult_dna[column]:\n",
    "\n",
    "        if value == 1:\n",
    "            value = 5\n",
    "\n",
    "        elif value == 2:\n",
    "            value = 4\n",
    "\n",
    "        elif value == 3:\n",
    "            value = 3\n",
    "\n",
    "        elif value == 4:\n",
    "            value = 2\n",
    "\n",
    "        elif value == 5:\n",
    "            value = 1\n",
    "\n",
    "        placeholder_lst.append(value)\n",
    "\n",
    "    hult_dna[column+'n'] = placeholder_lst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Hult DNA Groups </h2>\n",
    "\n",
    "The following section groups questions by the leadership skills model of the Hult DNA available at available on <a href = \"https://www.hult.edu/blog/why-every-leader-needs-growth-mindset/\">Hult's website</a>\n",
    "    \n",
    " Essentially questions were grouped into the following 3 attributes:\n",
    " <br> \n",
    " \n",
    " 1.  Thinking\n",
    " \n",
    " 2. Communication\n",
    " \n",
    " 3. Teamwork\n",
    " \n",
    " <br> \n",
    "For all the questions in each attribute, the average was taken to determine each respondents overall tendency toward each attribute\n",
    " \n",
    " \n",
    "An additional column for 'Growth mindset' was also created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Group\n",
    "########################################\n",
    "\n",
    "# Growth/Fixed mindset, ['DNA_4']\n",
    "hult_dna['Growth mindset'] = hult_dna['DNA_4']\n",
    "\n",
    "\n",
    "# Positive thinking, ['DNA_3']['DNA_19'],['DNA_5']=['DNA_8']\n",
    "# ['need_improve_thiking'],['positive_thinking']\n",
    "hult_dna['thinking'] = hult_dna[['DNA_3', 'DNA_19','DNA_5','DNA_8']].mean(axis=1)\n",
    "\n",
    "########################################\n",
    "# Communicator/ Need_improve_communication, ['DNA_11'],['DNA_6']=['DNA_9']\n",
    "# ['DNA_2n'], ['DNA_12n'],['DNA_17']\n",
    "hult_dna['communication'] = hult_dna[['DNA_11', 'DNA_6','DNA_9','DNA_2n','DNA_12n','DNA_17']].mean(axis=1)\n",
    "\n",
    "########################################\n",
    "# Team player/ Independent, ['DNA_13'],['DNA_14'], ['DNA_16n'], \n",
    "# ['DNA_7']=['DNA_10'], ['DNA_19'],['DNA_20'],['DNA_21'],\n",
    "# ['DNA_1'],['DNA_15'],['DNA_18']\n",
    "\n",
    "hult_dna['teamwork'] = hult_dna[['DNA_13', 'DNA_14','DNA_16n','DNA_7','DNA_10','DNA_19',\n",
    "                      'DNA_20','DNA_21','DNA_1','DNA_15','DNA_18']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h2> Hult DNA modeling </h2>\n",
    "\n",
    "<br>\n",
    "This part includes:\n",
    "\n",
    "- Scaling data\n",
    "\n",
    "- Principal Component Analysis (PCA)\n",
    "\n",
    "- Using Hult DNA as main components for modeling\n",
    "\n",
    "- Clustering the observations by using KMeans\n",
    "<br>\n",
    "\n",
    "\n",
    "<h3> Scaling data </h3>\n",
    "\n",
    "To avoid biases in the results we make sure to only select our Hult DNA explanatory variables before we do any scaling. Later, the removed data can be added back and used to compare results.\n",
    "\n",
    "\n",
    "The next steps are then to \n",
    "\n",
    "* instantiate a StandardScaler() object\n",
    "* fit the scaler object Hult DNA variables\n",
    "* transform Hult DNA variables using the scaler object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping demographic information\n",
    "my_df_DNA = hult_dna.loc[:, ['Growth mindset','thinking','communication','teamwork' ]]\n",
    "\n",
    "# INSTANTIATING a StandardScaler() object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the scaler with the data\n",
    "scaler.fit(my_df_DNA)\n",
    "\n",
    "\n",
    "# TRANSFORMING our data after fit\n",
    "X_scaled = scaler.transform(my_df_DNA)\n",
    "\n",
    "\n",
    "# converting scaled data into a DataFrame\n",
    "DNA_scaled = pd.DataFrame(X_scaled)\n",
    "\n",
    "\n",
    "# reattaching column names\n",
    "DNA_scaled.columns = my_df_DNA.columns\n",
    "\n",
    "\n",
    "# checking pre- and post-scaling variance\n",
    "# print(pd.np.var(my_df_DNA), '\\n\\n')\n",
    "\n",
    "# # Growth mindset    0.596939\n",
    "# # thinking          0.341757\n",
    "# # communication     0.274067\n",
    "# # teamwork          0.231253\n",
    "\n",
    "# print(pd.np.var(DNA_scaled))\n",
    "\n",
    "# # Growth mindset    1.0\n",
    "# # thinking          1.0\n",
    "# # communication     1.0\n",
    "# # teamwork          1.0\n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> PCA </h3>\n",
    "\n",
    "<strong> The next step </strong> was to instantiate, fit, and transform a PCA model with no fixed number of components\n",
    "\n",
    "<strong>Then </strong> we can visualize the explained variance of each principal component using a ScreePlot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a PCA object with no limit to principal components\n",
    "pca = PCA(n_components = None,\n",
    "          random_state = 802)\n",
    "\n",
    "\n",
    "# FITTING and TRANSFORMING the DNA_scaled\n",
    "DNA_pca = pca.fit_transform(DNA_scaled)\n",
    "\n",
    "\n",
    "# calling the scree_plot function\n",
    "scree_plot(pca_object = pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: From the ScreePlot we determined that there is a drop in the marginal return of explained variance after <strong> 2 principial components </strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a new model using the first three principal components\n",
    "pca_2 = PCA(n_components = 2,\n",
    "                random_state = 802)\n",
    "\n",
    "\n",
    "# FITTING and TRANSFORMING the purchases_scaled\n",
    "DNA_pca_2 = pca_2.fit_transform(DNA_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each principal component can be measured indirectly by analyzing its factor loadings, We can then develop a persona for each principal component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "### Max PCA Model ###\n",
    "####################\n",
    "# transposing pca components (pc = MAX)\n",
    "factor_loadings = pd.DataFrame(pd.np.transpose(pca.components_))\n",
    "\n",
    "\n",
    "# naming rows as original features\n",
    "factor_loadings = factor_loadings.set_index(DNA_scaled.columns)\n",
    "\n",
    "\n",
    "##################\n",
    "### 2 PCA Model ###\n",
    "##################\n",
    "# transposing pca components (pc = 2)\n",
    "factor_loadings_2 = pd.DataFrame(pd.np.transpose(pca_2.components_))\n",
    "\n",
    "\n",
    "# naming rows as original features\n",
    "factor_loadings_2 = factor_loadings_2.set_index(DNA_scaled.columns)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "# print(f\"\"\"\n",
    "# MAX Components Factor Loadings\n",
    "# ------------------------------\n",
    "# {factor_loadings.round(2)}\n",
    "\n",
    "\n",
    "# 2 Components Factor Loadings\n",
    "# ------------------------------\n",
    "# {factor_loadings_2.round(2)}\n",
    "# \"\"\")\n",
    "\n",
    "\n",
    "# # # Output\n",
    "\n",
    "# # # MAX Components Factor Loadings\n",
    "# # # ------------------------------\n",
    "# # #                    0     1     2     3\n",
    "# # # Growth mindset -0.45 -0.89  0.11  0.01\n",
    "# # # thinking       -0.51  0.16 -0.68 -0.50\n",
    "# # # communication  -0.49  0.33  0.72 -0.36\n",
    "# # # teamwork       -0.54  0.27 -0.11  0.79\n",
    "\n",
    "\n",
    "# # # 2 Components Factor Loadings\n",
    "# # # ------------------------------\n",
    "# # #                    0     1\n",
    "# # # Growth mindset -0.45 -0.89\n",
    "# # # thinking       -0.51  0.16\n",
    "# # # communication  -0.49  0.33\n",
    "# # # teamwork       -0.54  0.27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our  2 Components Factor Loadings we see a neutral relationship between the 0th component and Hult DNA, this principal component was renamed <strong> \"All_rounded\"</strong>\n",
    "\n",
    "From our 2 Components Factor Loadings we see a strong negative relationship between the 1st component and Growth mindset of Hult DNA, this principal component was renamed <strong> \"Fixed_mindset\" </strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Components\n",
    "# 0\tAll_rounded\n",
    "# 1\tFixed_mindset\n",
    "\n",
    "# naming each principal component\n",
    "factor_loadings_2.columns = ['All_rounded',\n",
    "                             'Fixed_mindset']\n",
    "\n",
    "# checking the result\n",
    "factor_loadings_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing factor strengths per person\n",
    "X_pca_reduced = pca_2.transform(DNA_scaled)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "X_pca_df = pd.DataFrame(X_pca_reduced)\n",
    "\n",
    "# INSTANTIATING a StandardScaler() object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the scaler with the data\n",
    "scaler.fit(X_pca_df)\n",
    "\n",
    "\n",
    "# TRANSFORMING our data after fit\n",
    "X_scaled_pca = scaler.transform(X_pca_df)\n",
    "\n",
    "\n",
    "# converting scaled data into a DataFrame\n",
    "DNA_pca_scaled = pd.DataFrame(X_scaled_pca)\n",
    "\n",
    "\n",
    "# reattaching column names\n",
    "DNA_pca_scaled.columns = ['All_rounded',\n",
    "                             'Fixed_mindset']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> KMeans </h3>\n",
    "\n",
    "\n",
    "The aim is to develop an idea of how many clusters would be appropriate, and then to apply this number of clusters to a k-Means model. \n",
    "\n",
    "The following code prepares a scaled version of the factor loadings (i.e. principal components) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the inertia_plot() function\n",
    "inertia_plot(data = DNA_pca_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a k-Means object with three clusters\n",
    "kmeans_DNA = KMeans(n_clusters = 3,\n",
    "                         random_state = 802)\n",
    "\n",
    "\n",
    "# fitting the object to the data\n",
    "kmeans_DNA.fit(DNA_pca_scaled)\n",
    "\n",
    "\n",
    "# converting the clusters to a DataFrame\n",
    "DNA_kmeans_pca = pd.DataFrame({'Cluster': kmeans_DNA.labels_})\n",
    "\n",
    "\n",
    "# checking the results\n",
    "# print(DNA_kmeans_pca.iloc[: , 0].value_counts())\n",
    "\n",
    "###  Output\n",
    "# # 0    153\n",
    "# # 2    126\n",
    "# # 1    113"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h3>Chosing number of clusters</h3>\n",
    "<br>\n",
    "\n",
    "After few trials, we have decided to stay with 3 clusters because it is the amount of cluster that is possible and not too difficult to focus for the business. If we select more clusters, it will be too hard to organize between each cluster and might has a high cost.\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we classified data into clusters and see which clusters belong to which components from PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0\tAll_rounded\n",
    "# 1\tFixed_mindset\n",
    "\n",
    "\n",
    "# storing cluster centers\n",
    "centroids_DNA = kmeans_DNA.cluster_centers_\n",
    "\n",
    "\n",
    "# converting cluster centers into a DataFrame\n",
    "centroids_DNA_df = pd.DataFrame(centroids_DNA)\n",
    "\n",
    "\n",
    "# renaming principal components\n",
    "centroids_DNA_df.columns = ['All_rounded',\n",
    "                            'Fixed_mindset']\n",
    "\n",
    "\n",
    "# checking results (clusters = rows, pc = columns)\n",
    "centroids_DNA_df.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above, we can see the difference between each clusters\n",
    "- Cluster 0: people in this cluster are fixed mindset type\n",
    "- Cluster 1: people in this cluster are mixed between all rounded and fixed mindset\n",
    "- Cluster 2: people in this cluster are All rounded type\n",
    "\n",
    "Next, we change the cluster name and combine the output from the model with demographic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating demographic information with pca-clusters\n",
    "final_pca_clust_df = pd.concat([my_df.loc[ : , ['Current laptop', 'Next laptop',\n",
    "                                                'Program', 'Gender', 'age_range',\n",
    "                                                'Nationality2','Nationality_continent',\n",
    "                                                'customer_type']],\n",
    "                                DNA_kmeans_pca, DNA_pca_scaled],\n",
    "                                axis = 1)\n",
    "\n",
    "\n",
    "# renaming clusters\n",
    "cluster_names = {0 : 'Cluster 1',\n",
    "                 1 : 'Cluster 2',\n",
    "                 2 : 'Cluster 3'\n",
    "                }\n",
    "\n",
    "\n",
    "final_pca_clust_df['Cluster'].replace(cluster_names, inplace = True)\n",
    "\n",
    "\n",
    "# adding a productivity step\n",
    "data_df = final_pca_clust_df\n",
    "\n",
    "# data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><h2>Demographics with Hult DNA analysis</h2>\n",
    "<br>\n",
    "\n",
    "This part consists of testing hypothesis about laptop buyers, in relation to their demographics and Hult DNA personalities traits. Boxplots were used to visually represent different clusters, traits and demographic categories.\n",
    "Hypothesis\n",
    "\n",
    "<br>\n",
    "<strong>Hypothesis</strong><br>\n",
    "\n",
    "- Windows users show the tendency with weak tendency towards traits  related with growth mindset, thinking, communicating and team building. \n",
    "    - \tFor the current laptops – the hypothesis is confirmed for cluster 2,3. In cluster 1, there is almost no difference.\n",
    "    - \tFor the next laptops - the hypothesis is confirmed for cluster 2,3, but slightly rejected on cluster 1\n",
    "    - \tFor the customer_type - the hypothesis is confirmed for cluster 2,3, but slightly rejected on cluster 1\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Current laptop\n",
    "########################\n",
    "\n",
    "# All_rounded\n",
    "# fig, ax = plt.subplots(figsize = (12, 8))\n",
    "# sns.boxplot(x = 'Cluster',\n",
    "#             y = 'All_rounded',\n",
    "#             hue = 'Current laptop',\n",
    "#             data = data_df)\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current Window users demonstrate slightly more all_rounded personality compare \n",
    "based on <strong> Cluster2 and <strong> Cluster3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Current laptop\n",
    "########################\n",
    "\n",
    "# Fixed_mindset\n",
    "# fig, ax = plt.subplots(figsize = (12, 8))\n",
    "# sns.boxplot(x = 'Cluster',\n",
    "#             y = 'Fixed_mindset',\n",
    "#             hue = 'Current laptop',\n",
    "#             data = data_df)\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The window users showcase more growth mindset in terms of embracing changes than Mac users.\n",
    "The reason being that window users have more brands as options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################\n",
    "# # Next laptop\n",
    "# ########################\n",
    "\n",
    "# # All_rounded\n",
    "# fig, ax = plt.subplots(figsize = (12, 8))\n",
    "# sns.boxplot(x = 'Cluster',\n",
    "#             y = 'All_rounded',\n",
    "#             hue = 'Next laptop',\n",
    "#             data = data_df)\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Female demonstrate more all_rounded personality since female are tends to be \n",
    "more multi-tasks than male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################\n",
    "# # customer_type\n",
    "# ########################\n",
    "\n",
    "# # Fixed_mindset\n",
    "# fig, ax = plt.subplots(figsize = (12, 8))\n",
    "# sns.boxplot(x = 'Cluster',\n",
    "#             y = 'All_rounded',\n",
    "#             hue = 'customer_type',\n",
    "#             data = data_df)\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################\n",
    "# # customer_type\n",
    "# ########################\n",
    "\n",
    "# # Fixed_mindset\n",
    "# fig, ax = plt.subplots(figsize = (12, 8))\n",
    "# sns.boxplot(x = 'Cluster',\n",
    "#             y = 'Fixed_mindset',\n",
    "#             hue = 'customer_type',\n",
    "#             data = data_df)\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################\n",
    "# # Age\n",
    "# ########################\n",
    "\n",
    "# # All_rounded\n",
    "# fig, ax = plt.subplots(figsize = (12, 8))\n",
    "# sns.boxplot(x = 'Cluster',\n",
    "#             y = 'All_rounded',\n",
    "#             hue = 'age_range',\n",
    "#             data = data_df)\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the data collection from the university, the ages are most likely located between\n",
    "20 to 35. \n",
    "On average, the age between 26-30 showcases more all_rounded personality with the knowledge \n",
    "as well as the professional, life experience. \n",
    "\n",
    "This is further address that window users are more toward all-rounded personality,\n",
    "which Microsoft can have the target segment on age 26-30 with all-rounded\n",
    "personality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################\n",
    "# # Age\n",
    "# ########################\n",
    "\n",
    "# # Fixed_mindset\n",
    "# fig, ax = plt.subplots(figsize = (12, 8))\n",
    "# sns.boxplot(x = 'Cluster',\n",
    "#             y = 'Fixed_mindset',\n",
    "#             hue = 'age_range',\n",
    "#             data = data_df)\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The younger age demonstrate more fixed mindset \n",
    "since people are still perceiving the world with their own personality, \n",
    "which is less flexible to embrace the change and influenced more by the peers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
